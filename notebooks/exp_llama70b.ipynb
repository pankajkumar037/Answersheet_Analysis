{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "image_path = r\"C:\\Users\\panka\\OneDrive\\Desktop\\Cograd\\Answersheet_Analysis\\answer_sheet_1.jpg\"\n",
    "\n",
    "\n",
    "base64_image = encode_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Analyse precisely and do not hellusinate.Give question number and their Marks obtained in json format.consider that Question numbsr only which has Obtained marks handwritten,.Do not wite null or anything just laeve that .Give output in json format\n",
    "ignore total marks section\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question Number and Marks Obtained in JSON Format**\n",
      "\n",
      "Based on the provided image, the following questions have handwritten marks:\n",
      "\n",
      "*   Question 1: 10\n",
      "*   Question 2: 2\n",
      "*   Question 3: 3\n",
      "\n",
      "The JSON format for these questions is as follows:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"question1\": 10,\n",
      "    \"question2\": 2,\n",
      "    \"question3\": 3\n",
      "}\n",
      "```\n",
      "\n",
      "This output only includes the questions with handwritten marks, excluding any null or empty values.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "def chat_completion(prompt,base64_image):\n",
    " return client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.2-90b-vision-preview\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "answer=chat_completion(prompt=prompt,base64_image=base64_image).choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_Question_Paper= r\"C:\\Users\\panka\\OneDrive\\Desktop\\Cograd\\Answersheet_Analysis\\test_paper_1.jpg\"\n",
    "base64_image_Question_Paper= encode_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_Question_Paper = f\"\"\"\n",
    "Do not consider any answer sheet just current image.Give question number ,  questions and theirs max marks in json format if a  question has more than one subpart then give  question as their subpart but max maarks of combined.Give output in json format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "[\n",
      "  {\n",
      "    \"question_number\": 1,\n",
      "    \"question\": \"Question 1\",\n",
      "    \"max_marks\": 7\n",
      "  },\n",
      "  {\n",
      "    \"question_number\": 2,\n",
      "    \"question\": \"Question 2\",\n",
      "    \"max_marks\": 7\n",
      "  },\n",
      "  {\n",
      "    \"question_number\": 3,\n",
      "    \"question\": \"Question 3\",\n",
      "    \"max_marks\": 7\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Note: Since there are only three questions on the answer sheet, the output only includes these three questions. If there were more questions, they would be included in the output as well.\n"
     ]
    }
   ],
   "source": [
    "question=chat_completion(prompt=prompt_Question_Paper,base64_image=base64_image_Question_Paper).choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comnibe both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#few sort prompting for model\n",
    "outputs=\"\"\"\n",
    "\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"question_number\": \"Q1\",\n",
    "      \"description\": \"Instruction execution cycle\",\n",
    "      \"max_marks\": 5,\n",
    "      \"marks_obtained\": 2\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_combining_ocr=f\"\"\"\n",
    "  You are given two JSON objects: {answer}` and :{question}.\n",
    "\n",
    "- {question} contains a list of questions, subparts, descriptions, and maximum marks.\n",
    "- {answer}contains the marks obtained for each question.\n",
    "\n",
    "Your task is to merge these two JSONs and give output only json object.\n",
    "\n",
    "Return a **single valid JSON object** with all questions, subparts, `\"max_marks\"`, and `\"marks_obtained\"`.\n",
    "\n",
    "yout output will be like {outputs} .you will give just output not code\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"questions\": [\n",
      "    {\n",
      "      \"question_number\": \"Q1\",\n",
      "      \"description\": \"Question 1\",\n",
      "      \"max_marks\": 7,\n",
      "      \"marks_obtained\": 10\n",
      "    },\n",
      "    {\n",
      "      \"question_number\": \"Q2\",\n",
      "      \"description\": \"Question 2\",\n",
      "      \"max_marks\": 7,\n",
      "      \"marks_obtained\": 2\n",
      "    },\n",
      "    {\n",
      "      \"question_number\": \"Q3\",\n",
      "      \"description\": \"Question 3\",\n",
      "      \"max_marks\": 7,\n",
      "      \"marks_obtained\": 3\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def chat_completion(prompt):\n",
    " return client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.2-90b-vision-preview\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "combined_output=chat_completion(prompt=prompt_combining_ocr).choices[0].message.content\n",
    "print(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_final=f\"just tell me the topic and araange them according to obtained marks in ascending order considering this {combined_output}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion(prompt):\n",
    " return client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.2-90b-vision-preview\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Question Analysis\n",
      "\n",
      "Questions in ascending order of marks obtained:\n",
      "\n",
      "1. Q2 - Question 2 (2 marks)\n",
      "2. Q3 - Question 3 (3 marks)\n",
      "3. Q1 - Question 1 (10 marks)\n"
     ]
    }
   ],
   "source": [
    "final_answer=chat_completion(prompt=prompt_final).choices[0].message.content\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\panka\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\panka\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\panka\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pytesseract) (11.1.0)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract, opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86 pytesseract-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pytesseract.exe is installed in 'C:\\Users\\panka\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\panka\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pytesseract numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# Set Tesseract path if not added to PATH\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess image for better OCR performance\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    return img\n",
    "\n",
    "def extract_marks(image_path):\n",
    "    \"\"\"Extract marks from an answer sheet\"\"\"\n",
    "    img = preprocess_image(image_path)\n",
    "    text = pytesseract.image_to_string(img, config=\"--psm 6\")  # OCR extraction\n",
    "\n",
    "    # Use regex to find marks (e.g., 7/10, 8.5, 9, 10/10)\n",
    "    marks = re.findall(r'\\b\\d{1,2}(?:[./]\\d{1,2})?\\b', text)\n",
    "\n",
    "    return marks\n",
    "\n",
    "# Example Usage\n",
    "image_path = \"test_paper_1.jpg\"  # Update with the correct path\n",
    "marks_list = extract_marks(image_path)\n",
    "\n",
    "print(\"Extracted Marks:\", marks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
