{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9586d9bdc1749579840d0897eabb99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e273dd1ff9514d2f89bd1be2a1b6f333",
              "IPY_MODEL_1a35bc811b834758ad6917d31e5b1207",
              "IPY_MODEL_c3eaad90fbbe485abd8009ea8ce5ff9b"
            ],
            "layout": "IPY_MODEL_cbb2c86d9f384b1c8b2a1ea19b942b39"
          }
        },
        "e273dd1ff9514d2f89bd1be2a1b6f333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_831b6089956b41c1b0c430313738a4c4",
            "placeholder": "​",
            "style": "IPY_MODEL_2ebb0e9a97bb4009a0e5c719372df43a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1a35bc811b834758ad6917d31e5b1207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99723d78f4a345a8800e736510861941",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bef76041a0dc4c6ea2a1930a39fe8372",
            "value": 2
          }
        },
        "c3eaad90fbbe485abd8009ea8ce5ff9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f322cbcfeb4886a92f6901face0785",
            "placeholder": "​",
            "style": "IPY_MODEL_5fa474c1d2944d18a387165331da5631",
            "value": " 2/2 [00:17&lt;00:00,  7.54s/it]"
          }
        },
        "cbb2c86d9f384b1c8b2a1ea19b942b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831b6089956b41c1b0c430313738a4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebb0e9a97bb4009a0e5c719372df43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99723d78f4a345a8800e736510861941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef76041a0dc4c6ea2a1930a39fe8372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7f322cbcfeb4886a92f6901face0785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa474c1d2944d18a387165331da5631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66vmG5Zy4OSF",
        "outputId": "8d70d7a2-14df-489f-e632-048fa092b67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-i4d5nigx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-i4d5nigx\n",
            "  Resolved https://github.com/huggingface/transformers to commit 3a6ab46a0b85479d6fb0d6ce0bff2e48b4751ac4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.51.0.dev0-py3-none-any.whl size=11136115 sha256=2ba72ec47089e8af8ff7405f45cb78687b5b847cfae96537b9ccc7b5f45e980e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5whte4aq/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.50.2\n",
            "    Uninstalling transformers-4.50.2:\n",
            "      Successfully uninstalled transformers-4.50.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.51.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qwen_vl_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXRhj7uK4b8A",
        "outputId": "fa03bad7-0add-4dba-b843-9222b2659ba1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qwen_vl_utils\n",
            "  Downloading qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting av (from qwen_vl_utils)\n",
            "  Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (24.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from qwen_vl_utils) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->qwen_vl_utils) (2025.1.31)\n",
            "Downloading qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\n",
            "Downloading av-14.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av, qwen_vl_utils\n",
            "Successfully installed av-14.2.0 qwen_vl_utils-0.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2.5-VL-3B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b9586d9bdc1749579840d0897eabb99f",
            "e273dd1ff9514d2f89bd1be2a1b6f333",
            "1a35bc811b834758ad6917d31e5b1207",
            "c3eaad90fbbe485abd8009ea8ce5ff9b",
            "cbb2c86d9f384b1c8b2a1ea19b942b39",
            "831b6089956b41c1b0c430313738a4c4",
            "2ebb0e9a97bb4009a0e5c719372df43a",
            "99723d78f4a345a8800e736510861941",
            "bef76041a0dc4c6ea2a1930a39fe8372",
            "f7f322cbcfeb4886a92f6901face0785",
            "5fa474c1d2944d18a387165331da5631"
          ]
        },
        "id": "U93UeSVX4b4o",
        "outputId": "6c6b542f-fb10-4013-ece4-b1e1d45cd795"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9586d9bdc1749579840d0897eabb99f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ghlf-_bnYy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=\"/content/test_paper_1.jpg\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image_path},\n",
        "            {\"type\": \"text\", \"text\": \"Give question number and their  questions and thiers max marks in json format if a  question has more than one subpart then give  question as their subpart but max max of combined.Give output in json format\"},\n",
        "        ],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "kX8EE5fU4b2l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for inference\n",
        "text = processor.apply_chat_template(\n",
        "    messages, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "hAzQip8O4b0t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.to(\"cuda\")\n",
        "\n",
        "# Inference: Generation of the output\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=1021)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")"
      ],
      "metadata": {
        "id": "x9jbsWX44byp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the list into a properly formatted string\n",
        "formatted_output = \"\\n\".join(output_text).strip()\n",
        "\n",
        "Qn_paper_json=\"Extracted Text:\\n\" + formatted_output"
      ],
      "metadata": {
        "id": "CH73NKtO4bwT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Qn_paper_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1gF1b_f4buE",
        "outputId": "1f360747-d3b9-4ece-9cdd-b9230898f2cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"subparts\": [\n",
            "        {\n",
            "          \"subpart_number\": \"a\",\n",
            "          \"description\": \"RTL is used to describe\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"b\",\n",
            "          \"description\": \"Sign of the number is preserved in shift micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"c\",\n",
            "          \"description\": \"PC contains the address of\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"d\",\n",
            "          \"description\": \"What decisions are made in computer organization?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"e\",\n",
            "          \"description\": \"Convert (568)10->()2->()8->()\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"f\",\n",
            "          \"description\": \"Define micro-operation and cite an example of micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"g\",\n",
            "          \"description\": \"Differentiate fixed point and floating point representation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"h\",\n",
            "          \"description\": \"Why extra memory reference is needed in indirect memory address instruction?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"i\",\n",
            "          \"description\": \"Write the instruction to load and store accumulator register?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"j\",\n",
            "          \"description\": \"How 1 bit classify the type of instruction?\"\n",
            "        }\n",
            "      ],\n",
            "      \"max_marks\": 15\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"description\": \"With the help of flow diagram discuss instruction execution cycle.\",\n",
            "      \"max_marks\": 5\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"description\": \"Present a report on the use of common bus system for data transfer? Illustrate data transfer using common bus system through example.\",\n",
            "      \"max_marks\": 6\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"description\": \"Explain memory reference and register reference instructions with suitable examples.\",\n",
            "      \"max_marks\": 4\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answer_sheet_extraction"
      ],
      "metadata": {
        "id": "ILaJ0jmW62st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=\"/content/one.jpg\"\n",
        "\n",
        "example=\"\"\"\n",
        "{\n",
        "  \"questions\": [\n",
        "    {\n",
        "      \"question_number\": \"Q1\",\n",
        "      \"marks_obtained\": 10\n",
        "    },\n",
        "    {\n",
        "      \"question_number\": \"Q2\",\n",
        "      \"marks_obtained\": 2\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image_path},\n",
        "            {\"type\": \"text\", \"text\": f\"Give question number and their Marks obtained in json format.consider that Question numbsr only which has Obtained marks handwritten,.Do not wite null or anything just laeve that and do not hellusinate.Give output in json format.exampleformat is {example}.\"},\n",
        "        ],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "m_WDmh6W4br0"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for inference\n",
        "text = processor.apply_chat_template(\n",
        "    messages, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")"
      ],
      "metadata": {
        "id": "YzfH5zQD6j8k"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.to(\"cuda\")\n",
        "\n",
        "# Inference: Generation of the output\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")"
      ],
      "metadata": {
        "id": "_MdpzxhQ6j5H"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the list into a properly formatted string\n",
        "formatted_output = \"\\n\".join(output_text).strip()\n",
        "Answer_sheet_json_one=\"Extracted Text:\\n\" + formatted_output"
      ],
      "metadata": {
        "id": "Nm25PzZE6j28"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Answer_sheet_json_one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w222j9iNMRQ2",
        "outputId": "34155486-9714-42ab-a46a-ddfff2e632c3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"marks_obtained\": 22\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"marks_obtained\": 23\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"marks_obtained\": 24\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"marks_obtained\": 25\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q5\",\n",
            "      \"marks_obtained\": 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Answer_sheet_json=\"Extracted Text:\\n\" + formatted_output\n",
        "print(Answer_sheet_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RgD2qj66j1F",
        "outputId": "bee09893-28b5-4044-9a32-36f0a9f809bd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"marks_obtained\": 10\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"marks_obtained\": 2\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"marks_obtained\": 3\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"marks_obtained\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft16J4mD6jzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**merging and taking final output**"
      ],
      "metadata": {
        "id": "swIH8-D-94UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Qn_paper_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgE-THsY6jwi",
        "outputId": "d8d39936-d31f-483d-f7d9-9c9def5c41ed"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"subparts\": [\n",
            "        {\n",
            "          \"subpart_number\": \"a\",\n",
            "          \"description\": \"RTL is used to describe\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"b\",\n",
            "          \"description\": \"Sign of the number is preserved in shift micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"c\",\n",
            "          \"description\": \"PC contains the address of\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"d\",\n",
            "          \"description\": \"What decisions are made in computer organization?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"e\",\n",
            "          \"description\": \"Convert (568)10->()2->()8->()\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"f\",\n",
            "          \"description\": \"Define micro-operation and cite an example of micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"g\",\n",
            "          \"description\": \"Differentiate fixed point and floating point representation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"h\",\n",
            "          \"description\": \"Why extra memory reference is needed in indirect memory address instruction?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"i\",\n",
            "          \"description\": \"Write the instruction to load and store accumulator register?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"j\",\n",
            "          \"description\": \"How 1 bit classify the type of instruction?\"\n",
            "        }\n",
            "      ],\n",
            "      \"max_marks\": 15\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"description\": \"With the help of flow diagram discuss instruction execution cycle.\",\n",
            "      \"max_marks\": 5\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"description\": \"Present a report on the use of common bus system for data transfer? Illustrate data transfer using common bus system through example.\",\n",
            "      \"max_marks\": 6\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"description\": \"Explain memory reference and register reference instructions with suitable examples.\",\n",
            "      \"max_marks\": 4\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Answer_sheet_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0WewWmG6juf",
        "outputId": "20062da6-fb0b-4514-fc7f-1f4e24cb24b6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"marks_obtained\": 10\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"marks_obtained\": 2\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"marks_obtained\": 3\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"marks_obtained\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taking Out Combined Output**"
      ],
      "metadata": {
        "id": "Z7rOCG01DTd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "gX-wIgMR93h3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#few sort prompting for model\n",
        "outputs=\"\"\"\n",
        "\n",
        "{\n",
        "  \"questions\": [\n",
        "    {\n",
        "      \"question_number\": \"Q1\",\n",
        "      \"description\": \"Instruction execution cycle\",\n",
        "      \"max_marks\": 5,\n",
        "      \"marks_obtained\": 2\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt_combining_ocr=f\"\"\"\n",
        "  You are given two JSON objects: {Qn_paper_json}` and :{Answer_sheet_json}.\n",
        "\n",
        "- {Qn_paper_json} contains a list of questions, subparts, descriptions, and maximum marks.\n",
        "- {Answer_sheet_json}contains the marks obtained for each question.\n",
        "\n",
        "Your task is to merge these two JSONs and give output only json object.\n",
        "\n",
        "Return a **single valid JSON object** with all questions, subparts, `\"max_marks\"`, and `\"marks_obtained\"`.\n",
        "\n",
        "yout output will be like {outputs}\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nQP_tk4QCp7I"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)\n",
        "json_obj=response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x6sj6CZiJckK",
        "outputId": "b1763262-03bc-41b2-8d14-5aa51024b596"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"questions\": [\n",
            "    {\n",
            "      \"question_number\": \"Q1\",\n",
            "      \"subparts\": [\n",
            "        {\n",
            "          \"subpart_number\": \"a\",\n",
            "          \"description\": \"RTL is used to describe\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"b\",\n",
            "          \"description\": \"Sign of the number is preserved in shift micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"c\",\n",
            "          \"description\": \"PC contains the address of\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"d\",\n",
            "          \"description\": \"What decisions are made in computer organization?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"e\",\n",
            "          \"description\": \"Convert (568)10->()2->()8->()\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"f\",\n",
            "          \"description\": \"Define micro-operation and cite an example of micro-operation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"g\",\n",
            "          \"description\": \"Differentiate fixed point and floating point representation.\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"h\",\n",
            "          \"description\": \"Why extra memory reference is needed in indirect memory address instruction?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"i\",\n",
            "          \"description\": \"Write the instruction to load and store accumulator register?\"\n",
            "        },\n",
            "        {\n",
            "          \"subpart_number\": \"j\",\n",
            "          \"description\": \"How 1 bit classify the type of instruction?\"\n",
            "        }\n",
            "      ],\n",
            "      \"max_marks\": 15,\n",
            "      \"marks_obtained\": null\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q2\",\n",
            "      \"description\": \"With the help of flow diagram discuss instruction execution cycle.\",\n",
            "      \"max_marks\": 5,\n",
            "      \"marks_obtained\": 2\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q3\",\n",
            "      \"description\": \"Present a report on the use of common bus system for data transfer? Illustrate data transfer using common bus system through example.\",\n",
            "      \"max_marks\": 6,\n",
            "      \"marks_obtained\": null\n",
            "    },\n",
            "    {\n",
            "      \"question_number\": \"Q4\",\n",
            "      \"description\": \"Explain memory reference and register reference instructions with suitable examples.\",\n",
            "      \"max_marks\": 4,\n",
            "      \"marks_obtained\": 0\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afv22pmrFTl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "final Ans"
      ],
      "metadata": {
        "id": "w0z-RqVB6wyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By Qwen**"
      ],
      "metadata": {
        "id": "NnPW6CEKAXZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_final=f\"just tell me the topic and araange them according to obtained marks in ascending order\""
      ],
      "metadata": {
        "id": "MkT6MN-APHzT"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            #{\"type\": \"image\", \"image\": image_path},\n",
        "            {\"type\": \"text\", \"text\": prompt_final},\n",
        "        ],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "bXMgNXC-78xa"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for inference\n",
        "text = processor.apply_chat_template(\n",
        "    messages, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "image_inputs, video_inputs = process_vision_info(messages)\n",
        "inputs = processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    videos=video_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")"
      ],
      "metadata": {
        "id": "ueUWXuocAW5K"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.to(\"cuda\")\n",
        "\n",
        "# Inference: Generation of the output\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JQckV4hcAW2S",
        "outputId": "a1c03baf-0241-4b57-c493-d4676378ca80"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GenerativeModel' object has no attribute 'generate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-4803cae86527>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Inference: Generation of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m generated_ids_trimmed = [\n\u001b[1;32m      6\u001b[0m     \u001b[0mout_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerativeModel' object has no attribute 'generate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the list into a properly formatted string\n",
        "formatted_output = \"\\n\".join(output_text).strip()\n",
        "\n",
        "Answer_sheet_json=\"Extracted Text:\\n\" + formatted_output"
      ],
      "metadata": {
        "id": "2j6Fg0JTAWzd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Answer_sheet_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEgQNUfRAWxD",
        "outputId": "d994fbbc-d241-4954-be5d-83bd3273b919"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text:\n",
            "Sure, here are the questions sorted according to the obtained marks in ascending order:\n",
            "\n",
            "1. **Q4**\n",
            "   - Description: Explain memory reference and register reference instructions with suitable examples.\n",
            "   - Max Marks: 4\n",
            "   - Marks Obtained: 0\n",
            "\n",
            "2. **Q2**\n",
            "   - Description: With the help of flow diagram discuss instruction execution cycle.\n",
            "   - Max Marks: 5\n",
            "   - Marks Obtained: 2\n",
            "\n",
            "3. **Q3**\n",
            "   - Description: Present a report on the use of common bus system for data transfer? Illustrate data transfer using common bus system through example.\n"
          ]
        }
      ]
    }
  ]
}